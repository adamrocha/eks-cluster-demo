name: EKS Cluster CI/CD

concurrency:
  group: terraform-${{ github.ref_name }}
  cancel-in-progress: true

on:
  push:
    branches: [main, stage, dev]
  pull_request:
    branches: [main, stage, dev]
  delete:

permissions:
  contents: write

env:
  AWS_ACCOUNT_ID: ${{ vars.AWS_ACCOUNT_ID }}
  AWS_REGION: ${{ vars.AWS_REGION }}
  EKS_CLUSTER_NAME: eks-demo-cluster
  REPO_NAME: hello-world-demo
  IMAGE_TAG: 1.3.2
  TERRAFORM_VERSION: 1.13.1
  PYTHON_VERSION: 3.11

jobs:
  # Deploy infrastructure and Docker image
  terraform-apply:
    if: github.event_name != 'delete'
    name: Provision Infrastructure
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS credentials
        run: aws sts get-caller-identity

      - name: Cache Terraform plugins
        uses: actions/cache@v4
        with:
          path: ~/.terraform.d/plugin-cache
          key: terraform-${{ runner.os }}-${{ hashFiles('**/*.tf') }}
          restore-keys: terraform-${{ runner.os }}-

      - name: Terraform Format Check
        run: terraform -chdir=terraform fmt -check -recursive

      - name: Terraform Init
        run: terraform -chdir=terraform init

      - name: Terraform Validate
        run: terraform -chdir=terraform validate

      - name: Terraform Plan
        run: terraform -chdir=terraform plan -out=tfplan

      - name: Terraform Apply
        run: terraform -chdir=terraform apply -auto-approve tfplan

  # Check if branch deletion should trigger destroy
  check_condition:
    if: github.event_name == 'delete'
    uses: ./.github/workflows/destroy-logic.yml
    with:
      branch_prefixes: feature/,fix/,chore/

  # Destroy infrastructure on feature branch deletion
  terraform-destroy:
    name: Destroy Infrastructure
    runs-on: ubuntu-latest
    needs: check_condition
    if: needs.check_condition.outputs.should_destroy == 'true'
    environment:
      name: destroy-approval
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Terraform Init
        run: terraform -chdir=terraform init

      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} || true

      - name: Delete Kubernetes resources
        run: |
          kubectl delete -f manifests/hello-world-service.yaml --ignore-not-found=true || true
          kubectl delete -f manifests/hello-world-deployment.yaml --ignore-not-found=true || true
          kubectl delete -f manifests/hello-world-ns.yaml --ignore-not-found=true || true
          echo "Waiting for resources to be deleted..."
          sleep 30

      - name: Terraform Destroy
        run: terraform -chdir=terraform destroy -auto-approve

  # Update Kubernetes deployment
  deploy:
    if: github.event_name != 'delete'
    name: Update Deployment
    runs-on: ubuntu-latest
    needs: terraform-apply
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Update kubeconfig
        run: aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}

      - name: Apply Kubernetes manifests
        run: |
          kubectl apply -f manifests/hello-world-ns.yaml
          kubectl apply -f manifests/hello-world-deployment.yaml
          kubectl apply -f manifests/hello-world-service.yaml

      - name: Update deployment image
        run: |
          kubectl set image deployment/hello-world \
            -n hello-world-ns \
            hello-world=${{ env.AWS_ACCOUNT_ID }}.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com/${{ env.REPO_NAME }}:${{ env.IMAGE_TAG }}

      - name: Wait for rollout
        run: |
          if ! kubectl rollout status deployment/hello-world -n hello-world-ns --timeout=300s; then
            echo "::error::Deployment failed"
            kubectl get pods -n hello-world-ns -o wide
            kubectl logs -n hello-world-ns -l app=hello-world --tail=30 --all-containers=true || true
            
            if kubectl rollout history deployment/hello-world -n hello-world-ns &>/dev/null; then
              echo "Rolling back..."
              kubectl rollout undo deployment/hello-world -n hello-world-ns
            fi
            exit 1
          fi
